{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e57bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ed8ce",
   "metadata": {},
   "source": [
    "### In train/val/test folder we must keep different class video_clip images inside the corresponding class directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40663be0",
   "metadata": {},
   "source": [
    "## ├───test\n",
    "#### │   ├───Guard [ Guard_img_001.png,.......]\n",
    "#### │   ├───Kick [ Kick_img_001.png,.....]\n",
    "#### │   └───Punch [ Punch_img_001.png,......]\n",
    "## ├───train\n",
    "#### │   ├───Guard [ Guard_img_001.png]\n",
    "#### │   ├───Kick [ Kick_img_001.png]\n",
    "#### │   └───Punch [ Punch_img_001.png]\n",
    "## └───val\n",
    "####    ├───Guard [ Guard_img_001.png]\n",
    "####    ├───Kick [ Kick_img_001.png]\n",
    "####    └───Punch [ Punch_img_001.png]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb09641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-26 16:14:42.221321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-26 16:14:42.245480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-26 16:14:42.245860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.815GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2021-08-26 16:14:42.246388: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246577: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246659: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246727: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246823: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246869: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246968: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2021-08-26 16:14:42.246983: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-26 16:14:42.248892: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-26 16:14:42.260303: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3799900000 Hz\n",
      "2021-08-26 16:14:42.260845: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5620511a7470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-26 16:14:42.260903: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-08-26 16:14:42.265083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-26 16:14:42.265223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_RealDiv (TensorF [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowO [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 2048)              23564800  \n",
      "=================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor(IMG_SIZE = 224):\n",
    "    feature_extractor = keras.applications.ResNet50V2(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"max\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bd8113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Video_DataGenerator(keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, video_frames_path, size = 224,batch_size=32,clip_len=25,h=224,w=224,ch=3,shuffle=True,label_dict = {\"no_damage\":0,\"damage\":1}):\n",
    "        'Initialization'\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.video_frames_path = video_frames_path\n",
    "        \n",
    "        self.video_clip_list = glob.glob(self.video_frames_path+'*/*')\n",
    "        print(self.video_clip_list)\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.clip_len = clip_len\n",
    "\n",
    "        self.label_dict = label_dict\n",
    "        \n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.ch = ch\n",
    "        self.size = size\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.video_clip_list) / self.batch_size))\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.video_clip_list[k] for k in indexes]\n",
    "\n",
    "        X = np.empty((self.batch_size,self.clip_len,self.h,self.w,self.ch))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i,vid in enumerate(list_IDs_temp):\n",
    "\n",
    "            clip_features = []\n",
    "\n",
    "            f = glob.glob(vid+'/*.jpg')\n",
    "\n",
    "            for k,im in enumerate(f):\n",
    "\n",
    "                label = im.split('/')[5]\n",
    "                frame = cv2.imread(im)\n",
    "                frame = cv2.resize(frame,(self.size,self.size))\n",
    "                frame =  cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#                 feature = feature_extractor.predict(frame[None,])\n",
    "                clip_features.append(frame)\n",
    "                \n",
    "                if k == int(self.clip_len - 1) :\n",
    "                    break\n",
    "        \n",
    "\n",
    "            X[i] = np.array(clip_features)\n",
    "            y[i] = self.label_dict[label]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.video_clip_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3804376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_gen = Video_DataGenerator(train_path)\n",
    "\n",
    "val_gen = Video_DataGenerator(val_path)\n",
    "\n",
    "\n",
    "# for i in train_gen:\n",
    "#     print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a314313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "class Features_DataGenerator(keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, path,feature_dim=2048, size = 224,batch_size=32,clip_len=25,shuffle=True,label_dict = {\"no_damage\":0,\"damage\":1}):\n",
    "        'Initialization'\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path \n",
    "        self.video_clip_list = glob.glob(self.path+'*/*')\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.clip_len = clip_len\n",
    "\n",
    "        self.label_dict = label_dict\n",
    "        \n",
    "        self.features_dim  = feature_dim\n",
    "        \n",
    "        self.size = size\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.video_clip_list) / self.batch_size))\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.video_clip_list[k] for k in indexes]\n",
    "\n",
    "        X = np.empty((self.batch_size,self.clip_len,self.features_dim))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i,vid in enumerate(list_IDs_temp):\n",
    "\n",
    "            clip_features = []\n",
    "\n",
    "            f = glob.glob(vid+'/*.jpg')\n",
    "\n",
    "            for k,im in enumerate(f):\n",
    "\n",
    "                label = im.split('/')[5]\n",
    "                frame = cv2.imread(im)\n",
    "                frame = cv2.resize(frame,(self.size,self.size))\n",
    "                frame =  cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                feature = feature_extractor.predict(frame[None,])\n",
    "                clip_features.append(feature)\n",
    "                \n",
    "                if k == int(self.clip_len - 1) :\n",
    "                    break\n",
    "        \n",
    "\n",
    "            X[i] = np.array(clip_features).reshape(self.clip_len,-1)\n",
    "            y[i] = self.label_dict[label]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.video_clip_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02726c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = Features_DataGenerator(train_path)\n",
    "\n",
    "for i in train_gen:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8b46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
